import torch
import numpy as np
from eva5_final.yolov3.utils.datasets import LoadImagesAndLabels as YoloDataset
from eva5_final.yolov3.utils.datasets import letterbox
from eva5_final.yolov3.utils.parse_config import parse_data_cfg
from torchvision.datasets.folder import pil_loader

class ComboDataset(YoloDataset):
    def __init__(self, config, train=True):
        data_dict = parse_data_cfg(config.yolo_config.opt.data)
        YoloDataset.__init__(
            self,
            data_dict["train"] if train else data_dict["valid"],
            config.IMG_SIZE if train else config.yolo_config.opt.img_size[-1],
            config.BATCH_SIZE,
            augment=train,
            hyp=config.yolo_config.hyp,
            rect=config.yolo_config.opt.rect if train else True,
            cache_images=config.yolo_config.opt.cache_images,
            single_cls=config.yolo_config.opt.single_cls,
            mosiac=config.yolo_config.opt.mosiac
        )
        self.config = config

    def __getitem__(self, index):
        # getting data from yolo dataset
        yolo_data = YoloDataset.__getitem__(self, index)

        # getting input image (path to input image is generated by
        # yolo dataset, so using that)
        _, _, path, _ = yolo_data
        img = np.array(pil_loader(path))

        # resizing and letterbox-ing input image since yolo does this and probably needs it.
        img, ratio, pad = letterbox(img, self.config.IMG_SIZE, auto=False, scaleup=True)

        return img.astype(np.float32) / 255, None, yolo_data, None

    def __len__(self):
        return YoloDataset.__len__(self)

    @staticmethod
    def collate_fn(batch):
        orig_img, midas_data, yolo_data, planercnn_data = zip(*batch)  # transposed
        img, label, path, shapes = zip(*yolo_data)
        for i, l in enumerate(label):
            l[:, 0] = i  # add target image index for build_targets()

        return (
            torch.tensor(orig_img).permute(0, 3, 1, 2), 
            midas_data, 
            (
                torch.stack(img, 0),
                torch.cat(label, 0),
                path,
                shapes
            ),
            planercnn_data
        )